# -*- coding: utf-8 -*-
"""aiml_final_hackathon

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KejCnGDNY_rCRiStK-oE0l-V9-DGLgzl
"""

from google.colab import drive
drive.mount('/content/drive')

# importing required libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split

# Load dataset from Drive
path = '/content/drive/MyDrive/Indian Airlines.csv'
df = pd.read_csv(path)

print("Data loaded successfully!")
print("Shape:", df.shape)

# Displaying dataset
df.head()

print("\n--- BASIC DATA INFO ---")
print(df.info())

print("\n--- Missing Values ---")
print(df.isnull().sum())

print("\n--- Summary Statistics ---")
print(df.describe(include='all'))

print("\n--- Columns ---")
print(df.columns.tolist())

# Drop completely empty rows
df.dropna(how='all', inplace=True)

# Drop identifier columns if present
for col in ['Unnamed: 0', 'flight']:
    if col in df.columns:
        df.drop(columns=[col], inplace=True)

# ---------- EXPLORATORY DATA ANALYSIS (EDA) ----------

import matplotlib.pyplot as plt
import seaborn as sns

print("\nEXPLORATORY DATA ANALYSIS")

# 1. Price Distribution
plt.figure(figsize=(8,4))
sns.histplot(df['price'], bins=50, kde=True)
plt.title("Distribution of Flight Prices")
plt.xlabel("Price")
plt.ylabel("Frequency")
plt.show()

# 2. Airline vs Price
plt.figure(figsize=(12,6))
sns.boxplot(x='airline', y='price', data=df)
plt.xticks(rotation=90)
plt.title("Airline vs Flight Price")
plt.show()

# 3. Class vs Price
plt.figure(figsize=(6,4))
sns.boxplot(x='class', y='price', data=df)
plt.title("Class vs Price")
plt.show()

# 4. Stops vs Price
plt.figure(figsize=(6,4))
sns.boxplot(x='stops', y='price', data=df)
plt.title("Total Stops vs Price")
plt.show()

# 5. Source City vs Price
plt.figure(figsize=(10,5))
sns.boxplot(x='source_city', y='price', data=df)
plt.title("Source City vs Price")
plt.xticks(rotation=45)
plt.show()

# 6. Correlation Heatmap (numeric features only)
plt.figure(figsize=(10,6))
sns.heatmap(df.corr(numeric_only=True), annot=True, cmap='coolwarm', fmt=".2f")
plt.title("Correlation Heatmap (Numerical Features)")
plt.show()

print("\nkey relationships visualized successfully!")

numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()
print("\nNumeric Columns:", numeric_cols)

plt.figure(figsize=(14,6))
df[numeric_cols].boxplot()
plt.title("Boxplots of Numeric Features (Before Outlier Handling)")
plt.xticks(rotation=45)
plt.show()

def cap_outliers_iqr(df, cols):
    df = df.copy()
    for col in cols:
        Q1 = df[col].quantile(0.25)
        Q3 = df[col].quantile(0.75)
        IQR = Q3 - Q1

        lower = Q1 - 1.5 * IQR
        upper = Q3 + 1.5 * IQR

        # Cap values
        df[col] = np.where(df[col] < lower, lower,
                           np.where(df[col] > upper, upper, df[col]))
    return df

df = cap_outliers_iqr(df, numeric_cols)
print("\nOutliers capped successfully!")

plt.figure(figsize=(14,6))
df[numeric_cols].boxplot()
plt.title("Boxplots of Numeric Features (After Outlier Handling)")
plt.xticks(rotation=45)
plt.show()

# Drop rows with missing target (price)
# Ensures that rows without a valid 'price' value are removed,
# as they can't be used for model training or prediction.
if 'price' in df.columns:
    df = df.dropna(subset=['price'])

# Encode categorical columns using LabelEncoder
# Converts text labels (like airline names, city names, etc.) into numeric codes
# so that machine learning models can process them.
categorical_cols = df.select_dtypes(include=['object']).columns
label_encoders = {}
for col in categorical_cols:
    le = LabelEncoder()
    df[col] = le.fit_transform(df[col].astype(str))
    label_encoders[col] = le

# Display confirmation and dataset shape after encoding
print("\nCategorical columns encoded successfully!")
print("Current shape:", df.shape)

# Display first 10 rows to verify encoding
df.head(10)

# ---------- FEATURE SELECTION & TRAIN-TEST SPLIT ----------

from sklearn.model_selection import train_test_split

print("\n FEATURE SELECTION & DATA SPLITTING")

# If 'flight' column exists (and is not useful), drop it
if 'flight' in df.columns:
    df.drop('flight', axis=1, inplace=True)

# Define target and features
X = df.drop('price', axis=1)
y = df['price']

print("Feature columns:", list(X.columns))
print("Target column: price")

# Split the dataset (80% train, 20% test)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

print("\nData successfully split!")
print(f"Train set: {X_train.shape}")
print(f"Test set: {X_test.shape}")

# Optional — quick feature correlation with price
corr_with_price = df.corr(numeric_only=True)['price'].sort_values(ascending=False)
print("\nTop features correlated with price:\n", corr_with_price)

# ---------- FINAL MODEL TRAINING & SAVING ----------

from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import numpy as np
import joblib

print("\n FINAL MODEL TRAINING & SAVING")

# Use only two efficient models
models = {
    "Linear Regression": LinearRegression(),
    "Random Forest": RandomForestRegressor(
        random_state=42,
        n_estimators=80,   # slightly reduced for faster training
        max_depth=12       # limits overfitting + faster runtime
    )
}

results = {}

for name, model in models.items():
    print(f"\nTraining {name}...")
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)

    mae = mean_absolute_error(y_test, y_pred)
    mse = mean_squared_error(y_test, y_pred)
    rmse = np.sqrt(mse)
    r2 = r2_score(y_test, y_pred)

    results[name] = {"MAE": mae, "RMSE": rmse, "R2": r2}

# Compare models
print("\nModel Performance Summary:")
for name, metrics in results.items():
    print(f"{name}: R2={metrics['R2']:.4f}, RMSE={metrics['RMSE']:.2f}, MAE={metrics['MAE']:.2f}")

# Select best model automatically
best_model_name = max(results, key=lambda x: results[x]["R2"])
best_model = models[best_model_name]

print(f"\nBest model selected: {best_model_name}")

# ---------- SAVE THE BEST MODEL (Fixed name: Random Forest_model.pkl) ----------
# We want the filename to always be 'Random Forest_model.pkl'
model_filename = "Random Forest_model.pkl"
joblib.dump(best_model, model_filename)
print(f" Model saved successfully as '{model_filename}'")

# ---------- SAVE MODEL COLUMNS ----------
joblib.dump(X_train.columns.tolist(), "model_columns.pkl")
print(" model_columns.pkl saved successfully!")

print("\nAll files are ready for Streamlit frontend.")

!ls -lh "Random Forest_model.pkl" model_columns.pkl

#---feature importance visualisation
import matplotlib.pyplot as plt
import seaborn as sns
import joblib

# Load the best model (Random Forest)
best_model = joblib.load("Random Forest_model.pkl")

# Get feature importances
importances = best_model.feature_importances_
feature_names = X.columns
importance_df = pd.DataFrame({
    "Feature": feature_names,
    "Importance": importances
}).sort_values(by="Importance", ascending=False)

# Display top features
print("Top 10 Important Features:")
print(importance_df.head(10))

# Plot feature importance
plt.figure(figsize=(10, 6))
sns.barplot(x="Importance", y="Feature", data=importance_df.head(15), palette="viridis")
plt.title("Top 15 Feature Importances (Random Forest)")
plt.xlabel("Importance Score")
plt.ylabel("Feature Name")
plt.show()

# ---------- FLIGHT DATA CLUSTERING USING K-MEANS ----------

# Import necessary libraries
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt
import seaborn as sns

# Step 1: Scale numerical features ('duration', 'days_left', 'price')
# Scaling is done to ensure all features contribute equally to clustering.
scaler = StandardScaler()
X_scaled = scaler.fit_transform(df[['duration', 'days_left', 'price']])

# Step 2: Apply K-Means clustering with 3 clusters
# K-Means groups flights into clusters based on their numeric characteristics.
kmeans = KMeans(n_clusters=3, random_state=42)
df['Cluster'] = kmeans.fit_predict(X_scaled)

# Step 3: Display average values of key features per cluster
# This helps understand how each cluster differs in terms of duration, price, etc.
print(df.groupby('Cluster')[['duration', 'days_left', 'price']].mean())

# Step 4: Visualize the clusters on a scatter plot
# Each color represents a cluster of flights with similar characteristics.
plt.figure(figsize=(10, 6))
sns.scatterplot(
    data=df,
    x='duration',
    y='price',
    hue='Cluster',
    palette='Set2'
)
plt.title("K-Means Clusters: Flight Groups by Duration & Price")
plt.show()

# Step 5: Compare actual vs predicted prices across clusters (if available)
# Useful when a model-generated price column exists to analyze prediction behavior by group.
if 'predicted_price' in df.columns:
    cluster_comparison = df.groupby('Cluster')[['price', 'predicted_price']].mean()
    print("\nCluster-wise Price Comparison:\n", cluster_comparison)

"""Cluster 0 → short flights, lower price

Cluster 1 → extremely high-priced flights (premium/long distance)

Cluster 2 → medium-long flights, moderate price

"""

# ---------- CLUSTER SUMMARY ----------

# Flights per cluster
print("\nFlights per Cluster:")
print(df['Cluster'].value_counts())

# Cluster vs Class
print("\nCluster vs Class:")
for cluster, group in df.groupby('Cluster'):
    print(f"\nCluster {cluster}")
    print(group['class'].value_counts())
    print("-" * 40)  # separator line

# Cluster vs Airline
print("\nCluster vs Airline:")
for cluster, group in df.groupby('Cluster'):
    print(f"\nCluster {cluster}")
    print(group['airline'].value_counts())
    print("-" * 40)  # separator line

#cluster visualisation
import matplotlib.pyplot as plt
import seaborn as sns

# Visualize price distribution per cluster
plt.figure(figsize=(8,5))
sns.boxplot(x='Cluster', y='price', data=df)
plt.title("Price Distribution across Clusters")
plt.xlabel("Cluster")
plt.ylabel("Price")
plt.show()

# Duration vs Price colored by Cluster
plt.figure(figsize=(8,5))
sns.scatterplot(x='duration', y='price', hue='Cluster', data=df, palette='viridis', alpha=0.6)
plt.title("Clusters based on Duration & Price")
plt.xlabel("Duration (hrs)")
plt.ylabel("Price (₹)")
plt.show()

# Class vs Cluster count
plt.figure(figsize=(7,4))
sns.countplot(x='Cluster', hue='class', data=df)
plt.title("Class Distribution within Clusters")
plt.xlabel("Cluster")
plt.ylabel("Number of Flights")
plt.legend(title="Class", labels=["Economy (0)", "Business (1)"])
plt.show()

# ---------- MODEL INSIGHTS ----------

print("=== MODEL PERFORMANCE INSIGHTS ===")
print("\nWe trained two models:")
print("Linear Regression  → Simpler, interpretable model")
print("Random Forest       → Complex, high-accuracy model")

print("\nBased on R² and RMSE scores:")
print("→ Linear Regression R² ≈ 0.90")
print("→ Random Forest R² ≈ 0.97 (selected as best model)")
print("\nHence, Random Forest is saved as the final model for predicting flight prices accurately.")


# ---------- CLUSTERING INSIGHTS ----------

print("\n\n=== CLUSTERING INSIGHTS ===")
print("→ K-Means formed 3 clusters:")
print("  Cluster 0: Mostly Economy, low–mid price flights.")
print("  Cluster 1: Premium or Business class flights — higher average price (≈ ₹55,000).")
print("  Cluster 2: Moderate duration and price flights, mixed category.")

print("\nCluster 1 having very high mean price (₹55k+) suggests Business or long-haul flights.")
print("Cluster 0 and 2, with mean prices ~₹7k–₹9k, correspond mostly to Economy and regional flights.")


# ---------- BUSINESS INSIGHT ----------

print("\n\n=== BUSINESS INSIGHT ===")
print("The model can help airlines or travel platforms to:")
print("- Predict and dynamically adjust prices based on timing, duration, and airline.")
print("- Understand market segmentation through clusters —")
print("  e.g., Economy vs Business patterns, city-based demand.")
print("- Optimize promotional offers for specific passenger groups.")


# ----------  VISUAL COMPARISON ----------

import seaborn as sns
import matplotlib.pyplot as plt

plt.figure(figsize=(8,5))
sns.barplot(x='Cluster', y='price', data=df, estimator='mean', ci=None, palette='Set2')
plt.title("Average Price per Cluster")
plt.xlabel("Cluster")
plt.ylabel("Average Flight Price (₹)")
plt.show()

import joblib
import numpy as np
import pandas as pd
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error

# ---------- LOAD SAVED MODEL ----------
model_filename = "Random Forest_model.pkl"
loaded_model = joblib.load(model_filename)
print(f"Model '{model_filename}' loaded successfully!\n")

# ---------- MAKE PREDICTIONS ----------
y_pred = loaded_model.predict(X_test)

# ---------- EVALUATE PERFORMANCE ----------
r2 = r2_score(y_test, y_pred)
mae = mean_absolute_error(y_test, y_pred)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))

print("=== FINAL MODEL EVALUATION ON TEST SET ===")
print(f"R² Score: {r2:.4f}")
print(f"MAE: {mae:.2f}")
print(f"RMSE: {rmse:.2f}")

# ---------- SAVE PREDICTIONS ----------
pred_df = pd.DataFrame({
    "Actual_Price": y_test,
    "Predicted_Price": y_pred
})
pred_df.to_csv("flight_price_predictions.csv", index=False)

print("\n Predictions saved as 'flight_price_predictions.csv'!")
print("You can open this file to see how well the model predicted flight prices.")

"""import joblib
import pandas as pd
import numpy as np
import sys

# ---------- LOAD MODEL ----------
model = joblib.load("Random Forest_model.pkl")
expected_features = list(model.feature_names_in_)
print("Model expects", len(expected_features), "features.")

# ---------- LOAD LABEL ENCODERS (from training) ----------
try:
    label_encoders
except NameError:
    label_encoders = globals().get("label_encoders", {})

# ---------- USER INPUT ----------
user_input = {
    "airline": "IndiGo",          # try changing to 'XYZ_Air' to test invalid case
    "source_city": "Delhi",
    "destination_city": "Mumbai",
    "departure_time": "Morning",
    "arrival_time": "Night",
    "stops": "zero",
    "class": "Economy",
    "duration": 2.45,
    "days_left": 25
}

# ---------- VALIDATION ----------
invalid_entries = []

for col, val in user_input.items():
    if col in label_encoders:  # if encoder available
        known_classes = set(label_encoders[col].classes_)
        if str(val) not in known_classes:
            invalid_entries.append(f"Invalid {col}: '{val}'. Valid options: {sorted(known_classes)}")

if invalid_entries:
    print("\n⚠️ Invalid user input detected!")
    for msg in invalid_entries:
        print(msg)
    sys.exit("❌ Prediction aborted due to invalid input.")

# ---------- PREPARE INPUT ----------
def suffixify(s):
    return str(s).replace(" ", "_").replace("/", "_").replace("-", "_")

row = {feat: 0 for feat in expected_features}

# Fill numeric
for num_col in ["duration", "days_left"]:
    if num_col in user_input:
        row[num_col] = float(user_input[num_col])

# Encode 'class'
if "class" in expected_features:
    if "class" in label_encoders:
        row["class"] = int(label_encoders["class"].transform([user_input["class"]])[0])
    else:
        row["class"] = 0 if user_input["class"].lower().startswith("econ") else 1

# One-hot encoding style fill
for feat in expected_features:
    if "_" in feat:
        prefix, suffix = feat.split("_", 1)
        val = user_input.get(prefix)
        if val and suffixify(val).lower() == suffixify(suffix).lower():
            row[feat] = 1

# Handle label-encoded columns (like airline, city, etc.)
for feat in label_encoders.keys():
    if feat in expected_features:
        try:
            row[feat] = int(label_encoders[feat].transform([user_input[feat]])[0])
        except Exception:
            pass

input_df = pd.DataFrame([row], columns=expected_features)
input_df = input_df.apply(pd.to_numeric, errors="coerce").fillna(0)

# ---------- PREDICT ----------
predicted_price = model.predict(input_df)[0]
print(f"\nPredicted Flight Price: ₹{predicted_price:,.2f}")"""
import joblib
import pandas as pd
import numpy as np
import sys

# ---------- LOAD MODEL ----------
model = joblib.load("Random Forest_model.pkl")
expected_features = list(model.feature_names_in_)
print("Model expects", len(expected_features), "features.")

# ---------- LOAD LABEL ENCODERS (from training) ----------
try:
    label_encoders
except NameError:
    label_encoders = globals().get("label_encoders", {})

# ---------- USER INPUT ----------
user_input = {
    "airline": "IndiGo",          # case-insensitive now
    "source_city": "Delhi",
    "destination_city": "Mumbai",
    "departure_time": "Morning",
    "arrival_time": "Night",
    "stops": "zero",
    "class": "Economy",
    "duration": 2.45,
    "days_left": 25
}

# ---------- VALIDATION (case-insensitive) ----------
invalid_entries = []

for col, val in user_input.items():
    if col in label_encoders:  # if encoder available
        known_classes = {cls.lower() for cls in label_encoders[col].classes_}  # lowercased
        if str(val).lower() not in known_classes:  # case-insensitive check
            invalid_entries.append(
                f"Invalid {col}: '{val}'. Valid options: {sorted(label_encoders[col].classes_)}"
            )

if invalid_entries:
    print("\n Invalid user input detected!")
    for msg in invalid_entries:
        print(msg)
    sys.exit(" Prediction aborted due to invalid input.")

# ---------- PREPARE INPUT ----------
def suffixify(s):
    return str(s).replace(" ", "_").replace("/", "_").replace("-", "_")

row = {feat: 0 for feat in expected_features}

# Fill numeric
for num_col in ["duration", "days_left"]:
    if num_col in user_input:
        row[num_col] = float(user_input[num_col])

# Encode 'class'
if "class" in expected_features:
    if "class" in label_encoders:
        row["class"] = int(label_encoders["class"].transform([user_input["class"]])[0])
    else:
        row["class"] = 0 if user_input["class"].lower().startswith("econ") else 1

# One-hot encoding style fill
for feat in expected_features:
    if "_" in feat:
        prefix, suffix = feat.split("_", 1)
        val = user_input.get(prefix)
        if val and suffixify(val).lower() == suffixify(suffix).lower():
            row[feat] = 1

# Handle label-encoded columns (like airline, city, etc.)
for feat in label_encoders.keys():
    if feat in expected_features:
        try:
            row[feat] = int(label_encoders[feat].transform([user_input[feat]])[0])
        except Exception:
            pass

input_df = pd.DataFrame([row], columns=expected_features)
input_df = input_df.apply(pd.to_numeric, errors="coerce").fillna(0)

# ---------- PREDICT ----------
predicted_price = model.predict(input_df)[0]
print(f"\nPredicted Flight Price: ₹{predicted_price:,.2f}")

df[(df['airline'] == 2) & (df['class'] == 1)]['price'].describe()

!pip install streamlit pyngrok pandas scikit-learn joblib

from google.colab import files
uploaded = files.upload()

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# import streamlit as st
# import pandas as pd
# import joblib
# import numpy as np
# 
# st.set_page_config(page_title="Flight Price Predictor", layout="centered")
# st.title(" Flight Ticket Price Prediction App")
# st.write("Enter your flight details below to get the estimated ticket price.")
# 
# # ---------- LOAD MODEL ----------
# model = joblib.load("Random Forest_model.pkl")
# label_encoders = joblib.load("label_encoders.pkl")
# 
# # ---------- LOAD DATASET ----------
# df = pd.read_csv("Indian Airlines.csv")
# 
# # ---------- INPUT FIELDS ON MAIN SCREEN ----------
# airline = st.selectbox("Airline", sorted(df["airline"].unique()))
# source_city = st.selectbox("Source City", sorted(df["source_city"].unique()))
# destination_city = st.selectbox("Destination City", sorted(df["destination_city"].unique()))
# departure_time = st.selectbox("Departure Time", sorted(df["departure_time"].unique()))
# arrival_time = st.selectbox("Arrival Time", sorted(df["arrival_time"].unique()))
# stops = st.selectbox("Stops", sorted(df["stops"].unique()))
# flight_class = st.selectbox("Class", sorted(df["class"].unique()))
# duration = st.number_input("Duration (hours)", min_value=0.5, max_value=10.0, value=2.0, step=0.1)
# days_left = st.number_input("Days left for departure", min_value=0, max_value=60, value=10)
# 
# # ---------- PREDICT BUTTON ----------
# if st.button("Predict Price"):
# 
#     # Prepare input data
#     input_data = pd.DataFrame({
#         "airline": [airline],
#         "source_city": [source_city],
#         "destination_city": [destination_city],
#         "departure_time": [departure_time],
#         "arrival_time": [arrival_time],
#         "stops": [stops],
#         "class": [flight_class],
#         "duration": [duration],
#         "days_left": [days_left]
#     })
# 
#     # Encode categorical variables
#     for col, le in label_encoders.items():
#         if col in input_data.columns:
#             input_data[col] = le.transform(input_data[col].astype(str))
# 
#     # Ensure columns match training order
#     model_columns = joblib.load("model_columns.pkl")
#     input_data = input_data.reindex(columns=model_columns, fill_value=0)
# 
#     # Predict
#     prediction = model.predict(input_data)[0]
# 
#     # ---------- SHOW OUTPUT ----------
#     st.markdown("---")
#     st.subheader(" Estimated Flight Price")
#     st.success(f"₹ {prediction:,.2f}")
# 
#     st.caption(f"{source_city}  {destination_city} | {airline} | {flight_class}")
# 
# # Footer
# st.markdown("---")
# st.info("Ensure the dataset and model match the same training data for accurate predictions.")
#

!pip install pyngrok

!pip install streamlit

from pyngrok import ngrok
import time

ngrok.set_auth_token("34vRlaiVE81TtMvvZGQRmJcub5l_4wVexciV5HnStivsZ1NRV")

ngrok.kill()

public_url = ngrok.connect(8501, bind_tls=True)
print("Your App URL:", public_url)

!streamlit run app.py --server.enableCORS false --server.enableXsrfProtection false &

time.sleep(5)

from pyngrok import ngrok
ngrok.set_auth_token("34vRlaiVE81TtMvvZGQRmJcub5l_4wVexciV5HnStivsZ1NRV")